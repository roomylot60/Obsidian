[Original Paper Link](https://arxiv.org/abs/1508.04025)

---

## Abstract

---
## 1. Introduction

---
## 2. Neural Machine Translation

---
## 3. Attention-based Models

### 3.1 Global Attention

### 3.2 Local Attention

### 3.3 Input-feeding Approach

---
## 4. Experiments

### 4.1 Training Details

### 4.2 English-German Results

### 4.3 German-English Results

---
## 5. Analysis

### 5.1 Learning curves

### 5.2 Effects of Translating Long Sentences

### 5.3 Choces of Attentional Architectures

### 5.4 Alignment Quality

### 5.5 Sample Translations

---
## 6. Conclusion
