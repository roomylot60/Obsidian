### Embedding

#### torch.nn.Embedding(num_embeddings, embedding_dim)
- `num_embeddings`과 `embedding_dim`을 정하는 기준은 다양한 요소와 상황에 따라 결정
1. **데이터의 크기와 복잡성**
    - `num_embeddings`*(int)*: 사용하려는 고유한 항목(예: 어휘의 크기, 카테고리의 수)의 총 개수입니다. 이 값은 데이터셋의 다양성과 복잡성에 따라 달라집니다.
    - `embedding_dim`*(int)*: 임베딩 벡터의 차원입니다. 일반적으로 이 값은 크게 설정될수록 모델의 표현 능력이 증가하지만, 계산 비용이 높아질 수 있습니다.
2. **컴퓨팅 리소스**
    - `embedding_dim`이 높을수록 연산량이 증가하므로, 사용 가능한 컴퓨팅 리소스를 고려하여 적절한 값을 선택해야 합니다.
3. **모델의 성능과 복잡성**
    - 임베딩 벡터의 차원이 클수록 모델은 더 복잡한 패턴과 관계를 학습할 수 있습니다. 하지만, 이는 과적합의 위험도 증가시킬 수 있으므로 조심스럽게 설정해야 합니다.
4. **이전 연구나 벤치마크**
    - 유사한 작업이나 데이터셋에서 얻은 성과를 참고하여 `num_embeddings`과 `embedding_dim`의 초기 값을 설정할 수 있습니다.
5. **하이퍼파라미터 튜닝**
    - 초기 모델 학습 후 성능을 평가하고, 필요한 경우 `num_embeddings`과 `embedding_dim`을 조절하여 모델의 성능을 향상시킬 수 있습니다.
