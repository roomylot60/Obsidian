[Original Paper Link](https://www.researchgate.net/publication/13853244_Long_Short-term_Memory)
[Ref.]()

---
## Abstract

---
## 1 INTRODUCTION

- Recurrent network : Feedback connetcions to store representations of recent input events in form of activations
- Existing short-term memory takes too much time for learning something and do not work well when minimal time lags getting longer between inputs and teacher signals
- **The problem**
	1. Error signals *explosion* in backprop
	2. Error signals *vanishing* in backprop
- **The remedy**
	- **Long Short-Term Memory; LSTM** : Recurrent Network architecture in conjunction with an appropriate gradient-based learning algorithm

---

## 2 PREVIOUS WORK
review previous work

---
## 3
outline of the detailed analysis of vanishing errors

---
## 4


---
## 5