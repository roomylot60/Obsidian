[Original Paper Link](https://arxiv.org/abs/1409.3215)
https://brunch.co.kr/@jean/5

---
![](Attatched/Pasted%20image%2020240328004006.png)

### Abstract
DNN 모델들은 어려운 학습 과제들에 대해 훌륭한 성능을 보여주는 강력한 모델들이다. 하지만 DNN이 대량의 레이블 학습 데이터에 대해서는 잘 작동하는 반면, 시퀀스 학습에 대한 매핑에는 사용되고 있지 않다. 해당 논문에서는 일반적인 end-to-end 접근으로 시퀀스 구조에 대한 최소한의 가정을 통한 시퀀스 학습을 제시한다. 우리의 방법은 다층화 된 LSTM을 입력 시퀀스를 벡터로 매핑하는 데에 쓰고, 다른 LSTM을 타겟 시퀀스를 벡터로 부터 디코드 하는 데에 사용한다. 우리의 주요 결과물은 WMT'14 dataset을 사용한 영어를 프랑스어로 번역하는 작업이며, LSTM을 통한 해당 작업은 총 테스트 데이터에 대해 BLEU score 34.8 점을 달성했다.

DNN 모델들이 어려운 학습 작업들에 대해 좋은 성능을 보여주고 있다. 레이블이 있는 많은 학습 데이터에 대해서는 잘 작동하지만 연속적인 작업에 대한 매핑은 잘 되고 있지 않다.
최소한의 추정을  통해 이루어지는 연속적 구조에 대한 학습에서의 end-to-end 접근
다층화된 LSTM을 입력 시퀀스를 고정된 차원으로 벡터화할 때 매핑에 사용
다른 다층 LSTM을 벡터로부터 타겟 시퀀스를 디코딩하는 데 사용

---

### 
