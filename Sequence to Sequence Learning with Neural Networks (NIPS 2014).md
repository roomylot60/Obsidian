[Original Paper Link](https://arxiv.org/abs/1409.3215)
https://brunch.co.kr/@jean/5

---
![](Attatched/Pasted%20image%2020240328004006.png)
(출처) https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice

---
### Abstract
- DNN 모델들은 어려운 학습 과제들에 대해 훌륭한 성능을 보여주는 강력한 모델들이다. 
- 하지만 DNN이 대량의 레이블 학습 데이터에 대해서는 잘 작동하는 반면, 시퀀스 학습에 대한 매핑에는 사용되고 있지 않다. 
- 해당 논문에서는 일반적인 end-to-end 접근으로 시퀀스 구조에 대한 최소한의 가정을 통한 시퀀스 학습을 제시한다. 우리의 방법은 다층화 된 LSTM을 입력 시퀀스를 벡터로 매핑하는 데에 쓰고, 다른 LSTM을 타겟 시퀀스를 벡터로 부터 디코드 하는 데에 사용한다. 
- 우리의 주요 결과물은 WMT'14 dataset을 사용한 영어를 프랑스어로 번역하는 작업이며, LSTM을 통한 해당 작업은 총 테스트 데이터에 대해 LSTM의 BLEU score가 사전 외 단어에 대해 패널티를 받고서 BLEU score 34.8 점을 달성했다. 
- 또한 LSTM은 장문에 대해서도 잘 작동했다. 
- 반면, 구문 기반의 SMT system이 같은 데이터에 대해 BLEU score 33.3을 달성했다. 
- 우리가 SMT system으로 생성한 LSTM을 1000개의 가설에 대해 재평가하였을 때, BLEU score는 36.5라는 이전의 최고 결과값에 근접한 결과를 얻었다. 
- LSTM은 문장 순서에 민감하고 상대적으로 능동태와 수동태에 불변하는 감각적 구문과 문장을 학습하였다. 
- 마지막으로 타겟 문장을 제외한 모든 문장 데이터의 단어의 순서를 거꾸로 하는 것이 source 문장과 타겟 문장 사이의 단기 의존성을 도입하여 LSTM의 성능을 확연히 향상시키고 최적화 문제를 줄이는 것을 확인했다.

---
### Introduction
- 심층 신경망(DNNs)은 매우 강력한 ML 모델로, 음성 인식과 시각적 물체 인식과 같은 어려운 문제에서 우수한 성능을 보여준다. 
- DNNs의 적정한 단계들로도 임의의 병렬 연산을 수행할 수 있기에 좋은 성능을 보여준다. 
- DNNs의 놀라운 특징 중 하나는 단 2개의 은닉 계층만으로 N 비트 숫자를 정렬할 수 있다는 것입니다. 
- 따라서 신경망은 전통적인 통계적 모델과 관련이 있음에도, 복잡한 연산을 학습합니다. 
- 또한, 큰 DNNs는 레이블 훈련 데이터가 네트워크의 매개변수를 명시하기에 충분한 정보를 가질 때 지도 학습 역전파로 훈련될 수 있습니다. 따라서 큰 DNN의 매개변수 설정이 좋은 결과를 달성하는 경우(예를 들어, 인간이 빠르게 문제를 해결할 수 있기 때문에) 지도 학습 역전파는 이러한 매개변수를 찾아 문제를 해결합니다.
